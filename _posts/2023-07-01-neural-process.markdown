---
layout: post
title:  "Exploiting Inferential Structure in Neural Processes"
date:   2023-07-01 23:59:59 +00:00
image: /images/neural-process.png
categories: research
author: "Dharmesh Tailor"
authors: "<strong>Dharmesh Tailor</strong>, Emtiyaz Khan, Eric Nalisnick"
venue: "39th Conference on Uncertainty in Artificial Intelligence (UAI)"
venue2: "5th Workshop on Tractable Probabilistic Modeling at UAI 2022"
paper: https://proceedings.mlr.press/v216/tailor23a.html
arxiv: https://arxiv.org/abs/2306.15169
poster: /docs/poster_uai23.pdf
---

This work provides a framework that allows the latent variable of Neural Processes to be given a rich prior defined by a graphical model. These distributional assumptions directly translate into an appropriate aggregation strategy for the context set. We describe a message-passing procedure that still allows for end-to-end optimization with stochastic gradients. We demonstrate the generality of our framework by using mixture and Student-t assumptions that yield improvements in function modelling and test-time robustness. 
